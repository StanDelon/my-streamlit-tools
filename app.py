import streamlit as st
import re
from collections import Counter
import pymorphy3
import pandas as pd
import hashlib
import os
import chardet

# ===== –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç 1: –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –º–∏–Ω—É—Å-—Å–ª–æ–≤ =====
def prepare_morph_analyzer():
    return pymorphy3.MorphAnalyzer()

def normalize_word(word, morph, force_exact=False):
    if force_exact or word.startswith('!'):
        return word.lstrip('!').lower()
    parsed = morph.parse(word.lower())[0]
    return parsed.normal_form

def parse_exclude_input(user_input):
    if '\n' in user_input:
        return [line.strip() for line in user_input.split('\n') if line.strip()]
    if '|' in user_input and '(' not in user_input and ')' not in user_input:
        return [item.strip() for item in user_input.split('|') if item.strip()]
    return [item.strip() for item in user_input.split(',') if item.strip()]

def get_exclusion_patterns(exclude_list, morph):
    patterns = []
    for item in exclude_list:
        item = item.strip()
        if not item:
            continue
        if item.startswith('/') and item.endswith('/'):
            pattern = item[1:-1]
            patterns.append((pattern, True, True))
            continue
        force_exact = item.startswith('!')
        if force_exact:
            item = item[1:]
        if '*' in item:
            escaped = re.escape(item)
            pattern = escaped.replace(r'\*', r'\w*')
            pattern = r'\b' + pattern + r'\b'
            patterns.append((pattern, False, True))
        else:
            words = re.findall(r'\w+', item.lower())
            normalized_words = [normalize_word(w, morph, force_exact) for w in words]
            pattern = r'\b' + r'\s+'.join(normalized_words) + r'\b'
            patterns.append((pattern, False, False))
    return patterns

def should_exclude(word, exclude_patterns):
    word_lower = word.lower()
    for pattern, is_regex, is_wildcard in exclude_patterns:
        try:
            if is_regex:
                if re.search(pattern, word_lower, re.IGNORECASE):
                    return True
            elif is_wildcard:
                if re.search(pattern, word_lower, re.IGNORECASE):
                    return True
            else:
                if re.fullmatch(pattern, word_lower, re.IGNORECASE):
                    return True
        except re.error:
            continue
    return False

def process_phrases(phrases, exclude_patterns, morph, min_word_length=3):
    words_counter = Counter()
    for phrase in phrases:
        words = re.findall(r'\b\w+\b', phrase.lower())
        for word in words:
            if len(word) >= min_word_length and not should_exclude(word, exclude_patterns):
                normalized = normalize_word(word, morph)
                words_counter[normalized] += 1
    sorted_words = sorted(words_counter.items(), key=lambda x: (-x[1], x[0]))
    return [word for word, count in sorted_words]

# ===== –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç 2: –•—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤ =====
def hash_phone(phone):
    phone_str = str(phone)
    return hashlib.sha256(phone_str.encode('utf-8')).hexdigest()

# ===== –í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å =====
st.title("–ú–æ–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã üîß")
tool = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç", ["–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –º–∏–Ω—É—Å-—Å–ª–æ–≤", "–•—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤"])

if tool == "–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –º–∏–Ω—É—Å-—Å–ª–æ–≤":
    st.header("–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –º–∏–Ω—É—Å-—Å–ª–æ–≤")
    phrases = st.text_area("–í–≤–µ–¥–∏—Ç–µ —Ñ—Ä–∞–∑—ã (–∫–∞–∂–¥–∞—è —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏)", height=150)
    exclude = st.text_area("–í–≤–µ–¥–∏—Ç–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é, | –∏–ª–∏ /—Ä–µ–≥—ç–∫—Å–ø/)", height=100)
    
    if st.button("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –º–∏–Ω—É—Å-—Å–ª–æ–≤–∞"):
        if not phrases:
            st.error("–í–≤–µ–¥–∏—Ç–µ —Ñ—Ä–∞–∑—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏!")
        else:
            morph = prepare_morph_analyzer()
            exclude_list = parse_exclude_input(exclude)
            exclude_patterns = get_exclusion_patterns(exclude_list, morph)
            phrases_list = [p.strip() for p in phrases.split('\n') if p.strip()]
            minus_words = process_phrases(phrases_list, exclude_patterns, morph)
            result = " ".join([f"-{word}" for word in minus_words])
            st.success("–†–µ–∑—É–ª—å—Ç–∞—Ç:")
            st.code(result)
            st.info(f"–ù–∞–π–¥–µ–Ω–æ {len(minus_words)} –º–∏–Ω—É—Å-—Å–ª–æ–≤.")

elif tool == "–•—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤":
    st.header("–•—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–æ–º–µ—Ä–æ–≤ —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤")
    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª (Excel/CSV)", type=["xlsx", "xls", "csv"])
    
    if uploaded_file:
        try:
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            
            phone_column = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–æ–ª–±–µ—Ü —Å —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏", df.columns)
            
            if st.button("–•—ç—à–∏—Ä–æ–≤–∞—Ç—å"):
                df[phone_column] = df[phone_column].apply(hash_phone)
                st.success("–ì–æ—Ç–æ–≤–æ! –ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫:")
                st.write(df.head())
                
                csv = df.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="–°–∫–∞—á–∞—Ç—å CSV",
                    data=csv,
                    file_name="hashed_phones.csv",
                    mime="text/csv"
                )
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞: {e}")
